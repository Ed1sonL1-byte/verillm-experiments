# 提示词模板配置 - 基于对话长度分类

prompts:
  # ===== SHORT INPUT: ~300 tokens =====
  # 适用场景：单轮简单问答，快速技术咨询
  short:
    name: "短对话"
    description: "单轮简单问答场景，测试基础推理能力"
    input_tokens: 300
    max_tokens: 4000
    min_tokens: 500
    templates:
      - |
        请解释一下区块链中的共识机制是什么？具体来说，PoW（工作量证明）和PoS（权益证明）有什么区别？各自的优缺点是什么？在什么场景下应该选择哪种共识机制？请给出具体的例子说明。

      - |
        我需要用Python实现一个简单的LRU缓存。要求：1）支持get和put操作；2）当缓存满时自动淘汰最久未使用的项；3）时间复杂度O(1)。请给出完整的实现代码，并解释你的设计思路，特别是如何保证O(1)的时间复杂度。

      - |
        什么是Transformer架构？它相比传统的RNN和LSTM有哪些优势？Self-attention机制是如何工作的？为什么Transformer在NLP任务上表现得这么好？请用通俗易懂的语言解释，并给出一些实际应用的例子。

      - |
        请分析一下分布式系统中的CAP定理。CAP分别代表什么？为什么三者不能同时满足？在实际系统设计中，应该如何权衡？请举例说明MongoDB、Redis、Cassandra等系统是如何做出选择的。

      - |
        解释一下Python中的装饰器（decorator）是什么？它的工作原理是什么？有哪些常见的使用场景？请给出2-3个实用的装饰器示例，并说明它们解决了什么问题。

  # ===== MEDIUM INPUT: ~1000 tokens =====
  # 适用场景：包含代码上下文、需求说明、多轮对话
  medium:
    name: "中等对话"
    description: "包含代码上下文和详细需求的复杂任务"
    input_tokens: 1000
    max_tokens: 6000
    min_tokens: 1000
    templates:
      - |
        我正在开发一个分布式机器学习训练系统，需要实现一个任务调度器。系统的基本架构如下：

        **背景信息：**
        - 有多个GPU节点（每个节点有4-8张GPU卡）
        - 训练任务有不同的优先级和资源需求
        - 需要支持任务排队、抢占、故障恢复
        - 每个任务需要指定：模型类型、数据集路径、GPU数量、优先级

        **已有代码框架：**
        ```python
        class TaskScheduler:
            def __init__(self, gpu_nodes):
                self.gpu_nodes = gpu_nodes  # List of GPU nodes
                self.task_queue = []
                self.running_tasks = {}

            def submit_task(self, task):
                # TODO: 实现任务提交逻辑
                pass

            def schedule(self):
                # TODO: 实现调度算法
                pass

            def handle_failure(self, task_id):
                # TODO: 实现故障处理
                pass
        ```

        **需求：**
        1. 实现submit_task方法：验证任务、加入队列、按优先级排序
        2. 实现schedule方法：为等待的任务分配GPU资源，考虑资源碎片化问题
        3. 实现handle_failure方法：任务失败时自动重试（最多3次）
        4. 支持任务抢占：高优先级任务可以抢占低优先级任务的GPU
        5. 添加监控：记录每个任务的等待时间、运行时间、资源利用率

        请提供完整的实现代码，包含详细注释和错误处理。同时说明你的调度算法选择理由。

      - |
        我在使用FastAPI开发一个用户认证服务，遇到了性能问题。当前实现如下：

        **当前代码：**
        ```python
        from fastapi import FastAPI, Depends, HTTPException
        from sqlalchemy.orm import Session
        import jwt

        app = FastAPI()

        def get_db():
            db = SessionLocal()
            try:
                yield db
            finally:
                db.close()

        @app.post("/login")
        async def login(username: str, password: str, db: Session = Depends(get_db)):
            user = db.query(User).filter(User.username == username).first()
            if not user or not verify_password(password, user.hashed_password):
                raise HTTPException(status_code=401, detail="Invalid credentials")
            token = jwt.encode({"user_id": user.id}, SECRET_KEY)
            return {"access_token": token}

        @app.get("/user/profile")
        async def get_profile(token: str, db: Session = Depends(get_db)):
            payload = jwt.decode(token, SECRET_KEY)
            user = db.query(User).filter(User.id == payload["user_id"]).first()
            return user.to_dict()
        ```

        **问题：**
        1. 每次请求都查询数据库，QPS只能达到500左右
        2. Token验证没有过期时间，存在安全隐患
        3. 没有实现token刷新机制
        4. 数据库连接池经常耗尽

        **优化要求：**
        - 添加Redis缓存层，缓存用户信息和token
        - 实现JWT的access token（15分钟）+ refresh token（7天）机制
        - 使用依赖注入优化数据库会话管理
        - 添加限流中间件防止暴力破解
        - 目标QPS：5000+

        请给出优化后的完整代码实现，并解释每个优化点的作用和预期效果。

      - |
        我需要设计一个实时数据处理pipeline，处理用户行为日志并进行异常检测。

        **系统需求：**
        - 数据源：Kafka topic，每秒10万条用户行为事件
        - 事件类型：登录、点击、购买、搜索等
        - 处理要求：实时计算用户行为特征，检测异常行为（如账号被盗、刷单等）
        - 延迟要求：端到端延迟 < 1秒

        **技术栈：**
        - Kafka作为消息队列
        - Flink或Spark Streaming做流处理
        - Redis存储用户最近行为特征
        - PostgreSQL存储异常事件

        **核心逻辑：**
        ```python
        # 异常检测规则（示例）
        def detect_anomaly(user_id, events):
            # 1. 短时间内大量登录失败
            # 2. 异地登录（IP地址突然变化）
            # 3. 购买行为异常（金额、频率）
            # 4. 深夜活跃异常
            pass
        ```

        **请实现：**
        1. Kafka消费者配置（考虑吞吐量和可靠性）
        2. Flink DataStream作业，实现滑动窗口聚合
        3. 异常检测算法（至少3种规则）
        4. 结果输出到Redis和PostgreSQL
        5. 监控指标：处理延迟、吞吐量、异常检测准确率

        请提供架构设计图的文字描述、完整代码实现、以及性能优化建议。

      - |
        我在开发一个区块链节点的P2P网络层，需要实现节点发现和消息广播机制。

        **背景：**
        - 去中心化网络，没有中心化的节点注册服务
        - 节点数量：1000-10000个
        - 需要快速发现新节点并同步区块链状态
        - 消息类型：交易广播、区块广播、节点发现

        **当前问题：**
        1. 使用简单的flooding算法广播消息，网络带宽浪费严重
        2. 新节点加入网络后，需要很长时间才能发现足够的peer
        3. 没有实现节点声誉机制，容易受到女巫攻击

        **技术要求：**
        ```python
        class P2PNode:
            def __init__(self, node_id, listen_port):
                self.node_id = node_id
                self.peers = {}  # peer_id -> PeerConnection
                self.routing_table = {}  # Kademlia DHT

            async def discover_peers(self):
                # TODO: 实现节点发现（基于Kademlia或Gossip协议）
                pass

            async def broadcast_message(self, message):
                # TODO: 实现高效的消息广播（避免重复转发）
                pass

            async def sync_blockchain(self, peer):
                # TODO: 从peer同步区块链数据
                pass
        ```

        **实现要求：**
        1. 使用Kademlia DHT实现节点发现
        2. 实现gossip协议优化消息广播（减少冗余）
        3. 添加bloom filter跟踪已见过的消息
        4. 实现节点评分机制（根据响应时间、可靠性等）
        5. 支持NAT穿透（STUN/TURN）

        请给出核心模块的实现代码，并解释协议选择的理由和预期的网络性能指标。

      - |
        我正在实现一个向量数据库的索引结构，用于大规模embedding检索。

        **需求场景：**
        - 存储1亿条768维的文本embedding向量
        - 查询需求：给定查询向量，返回最相似的top-k（k=10-100）个向量
        - 延迟要求：P99 < 50ms
        - 内存限制：单机64GB RAM

        **当前方案：**
        使用暴力搜索（brute force），计算查询向量与所有向量的余弦相似度，然后排序。

        ```python
        import numpy as np

        class VectorIndex:
            def __init__(self):
                self.vectors = []  # List of numpy arrays
                self.metadata = []  # Corresponding metadata

            def add(self, vector, meta):
                self.vectors.append(vector)
                self.metadata.append(meta)

            def search(self, query_vector, k=10):
                # Brute force search - too slow!
                similarities = [cosine_similarity(query_vector, v)
                               for v in self.vectors]
                top_k_indices = np.argsort(similarities)[-k:][::-1]
                return [self.metadata[i] for i in top_k_indices]
        ```

        **问题：**
        当前方案在1亿数据量下，单次查询需要几秒钟，完全无法满足需求。

        **优化任务：**
        1. 实现HNSW（Hierarchical Navigable Small World）索引结构
        2. 支持增量添加向量（不需要重建整个索引）
        3. 实现向量量化（PQ或ScalarQuantization）减少内存占用
        4. 支持过滤查询（根据metadata条件过滤）
        5. 持久化存储（支持索引保存和加载）

        请提供HNSW索引的核心实现代码，包括：
        - 索引构建算法
        - 搜索算法（greedy search）
        - 向量量化逻辑
        - 性能benchmark结果

        并说明在1亿数据量下的预期内存占用和查询延迟。

  # ===== LONG INPUT: ~3000 tokens =====
  # 适用场景：完整对话历史、大型文档、复杂上下文
  long:
    name: "长对话"
    description: "包含完整对话历史和复杂上下文的长文本任务"
    input_tokens: 3000
    max_tokens: 8000
    min_tokens: 1500
    templates:
      - |
        以下是一段关于分布式机器学习系统设计的完整对话历史，请基于这段对话，回答最后的问题。

        **对话历史：**

        用户：我想设计一个分布式训练系统，能够支持大规模深度学习模型训练。现在的问题是单机训练太慢了，一个100B参数的语言模型在单张A100上训练需要几个月。有什么好的方案吗？

        助手：针对大规模模型训练，有几种主流的并行策略：

        1. **数据并行**：将数据分片到多个GPU，每个GPU上运行完整模型的副本。适合模型能放入单GPU显存的情况。

        2. **模型并行**：将模型层切分到不同GPU。比如layer 0-10在GPU0，layer 11-20在GPU1。适合模型太大无法放入单GPU的情况。

        3. **流水线并行**：模型并行的改进版，将batch切分成多个micro-batch，在不同GPU上形成流水线，提高GPU利用率。

        4. **张量并行**：在张量维度上切分模型，比如将一个大的矩阵乘法分解到多个GPU上并行计算。

        对于100B参数的模型，建议使用**3D并行**：数据并行 + 流水线并行 + 张量并行的组合。

        用户：能详细说说3D并行是怎么工作的吗？具体怎么配置？

        助手：3D并行是DeepSpeed和Megatron-LM使用的策略，将三种并行方式结合：

        **架构示例（64张GPU）：**
        - 张量并行度：8（同一层的参数分布在8张GPU上）
        - 流水线并行度：4（模型分成4个stage）
        - 数据并行度：2（两个完整的模型副本）
        - 总GPU数：8 × 4 × 2 = 64

        **通信模式：**
        1. 张量并行：需要频繁的all-reduce通信，要求GPU间有高带宽（最好在同一节点内，通过NVLink连接）
        2. 流水线并行：只需要stage间传递激活值，通信量小，可以跨节点
        3. 数据并行：每个batch结束后需要同步梯度，通信量中等

        **内存优化：**
        - 使用ZeRO优化器状态分片（ZeRO stage 3）
        - 激活值重计算（activation checkpointing）
        - 卸载优化器状态到CPU内存

        用户：我的集群有8个节点，每个节点8张A100（80GB），节点间是100Gbps的网络。按照你说的3D并行，具体应该怎么配置？另外，我担心通信开销会很大，有什么优化方法吗？

        助手：针对你的硬件配置（8节点 × 8 GPU = 64张A100 80GB），我建议：

        **推荐配置：**
        ```python
        # DeepSpeed配置示例
        {
            "train_batch_size": 512,
            "train_micro_batch_size_per_gpu": 1,

            # 张量并行：8（同一节点内，利用NVLink）
            "tensor_parallel_size": 8,

            # 流水线并行：4（跨节点）
            "pipeline_parallel_size": 4,

            # 数据并行：2（自动推导）
            "data_parallel_size": 2,

            # ZeRO优化
            "zero_optimization": {
                "stage": 3,
                "offload_optimizer": false,
                "offload_param": false
            }
        }
        ```

        **通信优化策略：**

        1. **重叠计算与通信**：
        ```python
        # 伪代码
        with torch.cuda.stream(compute_stream):
            forward_compute()
        with torch.cuda.stream(comm_stream):
            all_reduce_gradients()  # 与下一层计算重叠
        ```

        2. **梯度累积**：
        减少通信频率，每N个micro-batch才同步一次梯度

        3. **混合精度训练**：
        使用FP16/BF16减少通信数据量（梯度大小减半）

        4. **压缩通信**：
        对梯度进行量化或稀疏化（如只传top-k梯度）

        **预期性能：**
        - 理论吞吐量：~500-600 samples/sec（100B模型）
        - 通信开销占比：15-25%
        - GPU利用率：70-85%

        用户：明白了。但是我还有一个问题，训练过程中如果有GPU故障怎么办？比如某张卡挂了，整个训练是不是就中断了？有没有容错机制？

        助手：是的，分布式训练的容错是个重要问题。常见的容错策略有：

        **1. Checkpoint机制（最基础）：**
        ```python
        # 定期保存checkpoint
        if global_step % checkpoint_interval == 0:
            save_checkpoint({
                'model_state': model.state_dict(),
                'optimizer_state': optimizer.state_dict(),
                'step': global_step,
                'loss': loss
            })
        ```

        问题：保存100B模型的checkpoint很慢（可能几十分钟），而且故障后需要从上一个checkpoint重启，损失大量训练进度。

        **2. 异步Checkpoint（优化）：**
        使用异步IO将checkpoint保存到共享存储，不阻塞训练：
        ```python
        checkpoint_thread = threading.Thread(
            target=save_checkpoint_async,
            args=(model_state,)
        )
        checkpoint_thread.start()
        # 训练继续，不等待保存完成
        ```

        **3. Elastic Training（推荐）：**
        使用torch.distributed.elastic或Ray Train，支持动态扩缩容：
        - 故障节点自动踢出
        - 剩余节点重新分配工作
        - 新节点可以动态加入

        **4. Redundant Computation（高级）：**
        为关键计算保留备份：
        - 同时在两组GPU上运行相同计算
        - 任一组成功即可继续
        - 成本翻倍，但可靠性大幅提升

        **实践建议：**
        对于你的场景，建议：
        1. 每1000步保存一次checkpoint（~10分钟）
        2. 使用异步保存，避免阻塞训练
        3. 集成torch.distributed.elastic，自动处理节点故障
        4. 监控GPU健康状态（温度、ECC错误等），提前预警

        用户：非常详细！最后一个问题，假设我要训练一个类似GPT-3的175B参数模型，按照刚才的配置，需要多长时间？成本大概是多少？

        **当前问题：**

        请基于以上对话，给出完整的训练计划，包括：

        1. **硬件需求分析**：
           - 175B模型需要多少GPU显存？
           - 3D并行配置应该如何调整（从100B扩展到175B）？
           - 是否需要增加节点数量？

        2. **训练时间估算**：
           - 假设训练数据量是300B tokens
           - 给出每秒处理的tokens数（考虑通信开销）
           - 总训练时间预估（天数）

        3. **成本估算**：
           - A100 GPU的云服务器成本（按市场价）
           - 总训练成本（GPU租用 + 存储 + 网络）
           - 与使用更多小型GPU的方案对比

        4. **风险与优化**：
           - 可能遇到的技术风险（内存不足、通信瓶颈等）
           - 针对性的优化方案
           - 训练过程中的监控指标

        5. **完整的训练脚本**：
           - DeepSpeed配置文件
           - 训练启动命令
           - Checkpoint和恢复逻辑
           - 监控和日志设置

        请给出详细的方案和代码实现。

      - |
        以下是一个复杂的系统设计场景，包含多个技术决策点。请仔细阅读背景信息，然后给出完整的系统设计方案。

        **项目背景：**

        某金融科技公司需要构建一个实时风控系统，用于检测信用卡欺诈交易。系统需求如下：

        **业务需求：**
        1. 实时性要求：每笔交易的风险评估必须在100ms内完成，否则用户体验受影响
        2. 准确性要求：欺诈检测召回率 > 95%，精确率 > 90%
        3. 规模：每秒处理10万笔交易（峰值可达20万）
        4. 可用性：系统可用性要求99.99%（年宕机时间 < 53分钟）

        **技术背景：**

        现有系统架构（存在问题）：
        ```
        用户交易 -> API网关 -> 规则引擎（同步） -> 机器学习模型（同步） -> 返回结果
        ```

        当前系统使用的技术栈：
        - API网关：Nginx + Flask
        - 规则引擎：Python + Redis（存储用户历史特征）
        - ML模型：XGBoost模型，部署在单个服务器上
        - 数据库：MySQL（存储交易记录）

        **当前问题：**

        1. **性能瓶颈**：
           - ML模型推理耗时80ms（单核CPU），无法满足100ms的要求
           - Redis频繁查询导致网络延迟
           - MySQL写入成为瓶颈（每秒只能写入5000条）

        2. **可扩展性问题**：
           - 无法水平扩展（模型加载在单台服务器）
           - 流量高峰期频繁超时

        3. **模型更新问题**：
           - 更新模型需要重启服务，导致几分钟的停机时间
           - 没有A/B测试机制，无法安全验证新模型

        4. **特征工程问题**：
           - 特征计算逻辑散落在多处代码，难以维护
           - 实时特征（如"过去1小时的交易次数"）计算不准确
           - 训练和推理特征不一致，导致线上线下效果差异

        **已有数据资源：**
        - 历史交易数据：10亿条交易记录，存储在数据仓库（Hive）
        - 用户画像数据：1000万用户的特征（存储在Redis）
        - 黑名单数据：已知的欺诈商户、设备指纹等（实时更新）

        **技术约束：**
        - 团队熟悉的技术栈：Python、Go、Kafka、Redis、PostgreSQL
        - 基础设施：Kubernetes集群（100+ nodes）、公有云环境
        - 预算：可以使用GPU服务器，但需要控制成本

        **之前的技术讨论：**

        团队内部讨论过几种方案：

        **方案A：模型服务化 + 微服务架构**
        - 将ML模型独立部署为微服务（使用TensorFlow Serving或TorchServe）
        - 使用Kubernetes进行自动扩缩容
        - 问题：特征计算仍然分散，难以保证一致性

        **方案B：流式处理架构**
        - 使用Kafka + Flink进行实时特征计算
        - 将计算好的特征写入Redis，模型只需读取
        - 问题：增加系统复杂度，需要维护流处理作业

        **方案C：特征平台 + 在线推理**
        - 构建统一的特征平台（如Feast）
        - 保证训练/推理特征一致性
        - 问题：引入新的依赖，学习成本高

        **方案D：边缘计算**
        - 将模型推理下沉到边缘节点
        - 减少网络延迟
        - 问题：模型更新和监控困难

        **具体技术细节：**

        当前ML模型特征（共150维）：
        1. 用户特征（30维）：年龄、性别、信用评分、历史交易统计等
        2. 交易特征（40维）：金额、商户类别、交易时间、地理位置等
        3. 序列特征（80维）：过去24小时的交易序列embedding

        特征计算代码示例：
        ```python
        def extract_features(transaction, user_id):
            # 用户特征（从Redis读取）
            user_profile = redis_client.get(f"user:{user_id}")

            # 实时统计特征（需要查询历史）
            recent_txns = mysql_client.query(
                f"SELECT * FROM transactions
                  WHERE user_id={user_id}
                  AND timestamp > NOW() - INTERVAL 1 HOUR"
            )
            txn_count_1h = len(recent_txns)

            # 序列特征（需要模型embedding）
            txn_sequence = get_recent_sequence(user_id, limit=50)
            sequence_emb = sequence_encoder.encode(txn_sequence)

            return {
                'user_age': user_profile['age'],
                'txn_amount': transaction['amount'],
                'txn_count_1h': txn_count_1h,
                'sequence_emb': sequence_emb,
                # ... 其他150维特征
            }
        ```

        问题：这个特征提取流程中，MySQL查询耗时50ms，序列编码耗时30ms，严重影响性能。

        **你的任务：**

        请设计一个完整的系统架构，解决上述所有问题。需要包含：

        1. **系统架构设计**：
           - 画出完整的系统架构图（用文字描述各个组件及其连接关系）
           - 说明数据流向和处理流程
           - 标注每个环节的预期延迟

        2. **技术选型和理由**：
           - 选择哪种方案（A/B/C/D或混合）？为什么？
           - 每个组件的技术选型（消息队列、数据库、缓存、模型服务等）
           - 如何保证100ms的延迟要求？

        3. **特征工程解决方案**：
           - 如何优化特征计算流程？
           - 如何保证训练/推理特征一致性？
           - 如何处理实时特征（如过去1小时的统计）？

        4. **模型服务设计**：
           - 如何部署ML模型（单模型 vs 模型ensemble）？
           - 如何实现模型的灰度发布和A/B测试？
           - 如何优化模型推理性能（量化、蒸馏、GPU加速等）？

        5. **高可用性设计**：
           - 如何保证99.99%的可用性？
           - 故障检测和自动恢复机制
           - 降级策略（当ML模型不可用时如何处理）

        6. **监控和运维**：
           - 需要监控哪些指标（性能、准确性、业务指标）？
           - 如何快速定位问题？
           - 如何进行容量规划？

        7. **成本优化**：
           - 预估总体成本（服务器、存储、网络）
           - 如何在性能和成本间平衡？

        8. **核心代码实现**：
           - 特征提取服务的伪代码
           - 模型推理服务的代码框架
           - Kafka消费者和Flink作业（如果使用流处理）

        请给出详尽的设计文档，包括架构图、技术选型理由、代码实现和性能评估。

      - |
        你是一个系统架构专家。以下是一个大型电商平台的技术演进历史和当前面临的挑战，请基于完整的上下文信息，给出系统重构方案。

        **公司背景：**

        某电商平台成立于2015年，目前已成长为日订单量100万的中型平台。技术团队从最初的5人成长到现在的200人。

        **技术演进历史：**

        **第一阶段（2015-2017）：单体应用**
        - 技术栈：PHP + MySQL + Redis
        - 架构：经典的LAMP架构，所有功能在一个代码仓库
        - 规模：日订单量 < 1000，单台服务器足够
        - 问题：随着业务增长，代码耦合严重，部署困难

        **第二阶段（2017-2019）：服务化改造**
        - 拆分为10个微服务：用户、商品、订单、支付、物流等
        - 引入Spring Cloud（公司决定从PHP迁移到Java）
        - 服务间通信：HTTP REST API
        - 问题：
          * 分布式事务难处理（订单 + 库存 + 支付的一致性）
          * 服务间调用链路长，性能下降
          * 团队对Java生态不熟悉，踩了很多坑

        **第三阶段（2019-2021）：中间件引入**
        - 引入消息队列（RabbitMQ）处理异步任务
        - 引入分布式事务框架（Seata）
        - 引入服务网格（Istio）
        - 数据库拆分：按业务垂直拆分，订单库、商品库、用户库独立
        - 问题：
          * 中间件太多，运维成本高
          * Istio性能开销大（增加20ms延迟）
          * Seata在高并发下不稳定

        **第四阶段（2021-现在）：云原生转型**
        - 迁移到Kubernetes
        - 引入服务网格（从Istio换成Linkerd）
        - 数据库开始分库分表（订单表已达10亿条）
        - 引入Elasticsearch做商品搜索
        - 问题：
          * 分库分表后，跨库查询困难（如订单列表页需要关联商品、用户信息）
          * Elasticsearch同步延迟（MySQL -> ES需要5-10秒）
          * 高峰期（大促）仍然会出现超时和限流

        **当前系统架构：**

        ```
        前端（React）
          ↓
        API网关（Kong）
          ↓
        微服务层（20+个服务）：
          - 用户服务（Java Spring Boot）
          - 商品服务（Java Spring Boot）
          - 订单服务（Go + gRPC）- 核心服务
          - 支付服务（Java）
          - 库存服务（Go）
          - 推荐服务（Python FastAPI + TensorFlow）
          - 搜索服务（封装Elasticsearch）
          ↓
        数据层：
          - MySQL主从集群（分库分表，16个物理库）
          - Redis集群（Cluster模式，6节点）
          - Elasticsearch集群（3节点）
          - Kafka（3节点）
        ```

        **当前性能指标：**
        - 平均响应时间：200ms（P99: 800ms）
        - 峰值QPS：50000（大促时）
        - 数据库连接池经常打满
        - Redis内存使用率：85%（接近上限）

        **近期发生的严重故障：**

        **故障1（2023.6）：订单服务雪崩**
        - 原因：订单服务调用库存服务超时，导致线程池耗尽
        - 影响：所有下单请求失败，持续30分钟
        - 损失：约10万订单丢失，直接经济损失500万
        - 临时措施：重启订单服务，增加超时时间
        - 根本原因未解决：服务间强依赖

        **故障2（2023.8）：数据库主库宕机**
        - 原因：慢SQL导致主库CPU 100%，主从切换失败
        - 影响：网站不可用2小时
        - 损失：品牌形象受损，用户流失
        - 临时措施：手动切换到从库
        - 遗留问题：主从延迟严重（平均5秒），影响读一致性

        **故障3（2023.11）：Redis集群脑裂**
        - 原因：网络抖动导致cluster分区
        - 影响：部分用户购物车数据丢失
        - 损失：用户投诉激增
        - 临时措施：Redis集群重启
        - 遗留问题：没有Redis数据持久化方案

        **业务方新需求（压力山大）：**

        1. **个性化推荐**：
           - 要求首页商品推荐根据用户实时行为调整
           - 延迟要求：< 100ms
           - 需要处理用户点击流数据（每秒10万事件）

        2. **实时库存**：
           - 当前库存数据有延迟（最多5秒），导致超卖
           - 要求实时扣减库存，严格防止超卖

        3. **大促支持**：
           - 双11预计流量是平时的10倍
           - 要求系统能够自动扩容，成本可控

        4. **数据分析**：
           - 运营团队要求实时大屏（GMV、订单量等指标）
           - 数据团队要求能够查询任意时间段的订单明细

        **技术团队的困境：**

        1. **技术债务**：代码中充斥着if-else，新功能开发困难
        2. **人员流动**：核心开发离职，代码没人敢动
        3. **技术栈混乱**：Java、Go、Python混用，缺乏统一标准
        4. **测试不足**：没有自动化测试，全靠人工测试，bug频发
        5. **监控缺失**：故障发生后才知道，缺乏主动预警

        **管理层的期望：**
        - 今年必须完成系统重构，支撑未来3年业务增长
        - 预算充足，可以采购新的基础设施
        - 但要求重构过程中不能影响业务（零停机）
        - 6个月内完成核心模块重构

        **你的任务：**

        作为新上任的技术架构师，请制定完整的系统重构方案：

        1. **问题诊断**：
           - 当前系统的核心问题是什么？（技术视角）
           - 哪些是需要优先解决的（按影响排序）？

        2. **重构策略**：
           - 选择大爆炸式重写还是渐进式重构？为什么？
           - 重构的优先级和阶段划分（6个月的详细计划）
           - 如何保证重构期间业务不受影响？

        3. **目标架构设计**：
           - 画出重构后的目标架构（用文字详细描述）
           - 技术选型（保留哪些，替换哪些，新引入哪些）
           - 如何解决服务间强依赖问题？
           - 如何解决数据一致性问题？

        4. **核心模块重构方案**：

           **订单服务重构：**
           - 如何处理分布式事务（订单+库存+支付）？
           - 如何优化数据库查询（已分库分表）？
           - 如何支持高并发下单（大促10倍流量）？

           **库存服务重构：**
           - 如何实现实时库存扣减，防止超卖？
           - 如何处理库存回滚（订单取消）？
           - 如何支持预占库存（用户加入购物车15分钟内保留）？

           **搜索服务重构：**
           - 如何减少MySQL到ES的同步延迟（从5秒降到100ms内）？
           - 如何支持复杂查询（价格区间、多条件筛选、排序）？
           - 如何优化搜索性能（P99 < 50ms）？

        5. **数据架构优化**：
           - 分库分表策略（当前16个库是否合理）？
           - 跨库查询解决方案（CQRS？数据冗余？）
           - 数据备份和容灾方案

        6. **可观测性建设**：
           - 监控体系（指标、日志、链路追踪）
           - 告警策略（如何提前预警）
           - 故障演练（混沌工程）

        7. **团队和流程**：
           - 如何推动技术栈统一？
           - 如何建立代码规范和review机制？
           - 如何补齐自动化测试？

        8. **风险控制**：
           - 重构过程中可能遇到的风险
           - 应对措施和回滚方案
           - 如何向管理层汇报进度？

        请给出一份完整的技术方案文档，包括架构设计、实施计划、风险评估和预期收益。

# 生成配置（默认值，可被prompt type覆盖）
generation_config:
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  do_sample: true
  repetition_penalty: 1.1
